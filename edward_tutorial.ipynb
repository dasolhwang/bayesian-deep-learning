{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import edward as ed\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import datasets\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from edward.models import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train),(X_test, y_test) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train)\n",
    "Y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_toy_dataset(N, w, noise_std=0.1):\n",
    "    D = len(w)\n",
    "    x = np.random.randn(N, D)\n",
    "    y = np.dot(x, w) + np.random.normal(0, noise_std, size=N)\n",
    "    return x, y\n",
    "\n",
    "N = 40  # number of data points\n",
    "D = 10  # number of features\n",
    "\n",
    "w_true = np.random.randn(D)\n",
    "X_train, y_train = build_toy_dataset(N, w_true)\n",
    "X_test, y_test = build_toy_dataset(N, w_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(X):\n",
    "    h = tf.tanh(tf.matmul(X, W_0) + b_0)\n",
    "    h = tf.tanh(tf.matmul(h, W_1) + b_1)\n",
    "    h = tf.matmul(h, W_2) + b_2\n",
    "    return tf.reshape(h, [-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "with tf.name_scope(\"model\"):\n",
    "    W_0 = Normal(loc=tf.zeros([D, 10]), scale=tf.ones([D, 10]), name=\"W_0\")\n",
    "    W_1 = Normal(loc=tf.zeros([10, 10]), scale=tf.ones([10, 10]), name=\"W_1\")\n",
    "    W_2 = Normal(loc=tf.zeros([10, 1]), scale=tf.ones([10, 1]), name=\"W_2\")\n",
    "    b_0 = Normal(loc=tf.zeros(10), scale=tf.ones(10), name=\"b_0\")\n",
    "    b_1 = Normal(loc=tf.zeros(10), scale=tf.ones(10), name=\"b_1\")\n",
    "    b_2 = Normal(loc=tf.zeros(1), scale=tf.ones(1), name=\"b_2\")\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [N, D], name=\"X\")\n",
    "    y = Normal(loc=neural_network(X), scale=0.1 * tf.ones(N), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/edward/util/random_variables.py:52: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  not np.issubdtype(value.dtype, np.float) and \\\n"
     ]
    }
   ],
   "source": [
    "# INFERENCE\n",
    "with tf.name_scope(\"posterior\"):\n",
    "    with tf.name_scope(\"qW_0\"):\n",
    "        qW_0 = Normal(loc=tf.Variable(tf.random_normal([D, 10]), name=\"loc\"),\n",
    "                  scale=tf.nn.softplus(\n",
    "                      tf.Variable(tf.random_normal([D, 10]), name=\"scale\")))\n",
    "    with tf.name_scope(\"qW_1\"):\n",
    "        qW_1 = Normal(loc=tf.Variable(tf.random_normal([10, 10]), name=\"loc\"),\n",
    "                  scale=tf.nn.softplus(\n",
    "                      tf.Variable(tf.random_normal([10, 10]), name=\"scale\")))\n",
    "    with tf.name_scope(\"qW_2\"):\n",
    "        qW_2 = Normal(loc=tf.Variable(tf.random_normal([10, 1]), name=\"loc\"),\n",
    "                  scale=tf.nn.softplus(\n",
    "                      tf.Variable(tf.random_normal([10, 1]), name=\"scale\")))\n",
    "    with tf.name_scope(\"qb_0\"):\n",
    "        qb_0 = Normal(loc=tf.Variable(tf.random_normal([10]), name=\"loc\"),\n",
    "                  scale=tf.nn.softplus(\n",
    "                      tf.Variable(tf.random_normal([10]), name=\"scale\")))\n",
    "    with tf.name_scope(\"qb_1\"):\n",
    "        qb_1 = Normal(loc=tf.Variable(tf.random_normal([10]), name=\"loc\"),\n",
    "                  scale=tf.nn.softplus(\n",
    "                      tf.Variable(tf.random_normal([10]), name=\"scale\")))\n",
    "    with tf.name_scope(\"qb_2\"):\n",
    "        qb_2 = Normal(loc=tf.Variable(tf.random_normal([1]), name=\"loc\"),\n",
    "                  scale=tf.nn.softplus(\n",
    "                      tf.Variable(tf.random_normal([1]), name=\"scale\")))\n",
    "\n",
    "inference = ed.KLqp({W_0: qW_0, b_0: qb_0,\n",
    "                     W_1: qW_1, b_1: qb_1,\n",
    "                     W_2: qW_2, b_2: qb_2}, data={X: X_train, y: y_train})\n",
    "#inference.run(logdir='log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 3s | Loss: 989.941\n"
     ]
    }
   ],
   "source": [
    "inference.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import edward as ed\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from edward.models import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_toy_dataset(N, w):\n",
    "    D = len(w)\n",
    "    x = np.random.normal(0.0, 2.0, size=(N, D))\n",
    "    y = np.dot(x, w) + np.random.normal(0.0, 0.05, size=N)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(arrays, batch_size):\n",
    "    \"\"\"Generate batches, one with respect to each array's first axis.\"\"\"\n",
    "    starts = [0] * len(arrays)  # pointers to where we are in iteration\n",
    "    while True:\n",
    "        batches = []\n",
    "        for i, array in enumerate(arrays):\n",
    "            start = starts[i]\n",
    "            stop = start + batch_size\n",
    "            diff = stop - array.shape[0]\n",
    "            if diff <= 0:\n",
    "                batch = array[start:stop]\n",
    "                starts[i] += batch_size\n",
    "            else:\n",
    "                batch = np.concatenate((array[start:], array[:diff]))\n",
    "                starts[i] = diff\n",
    "            batches.append(batch)\n",
    "        yield batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed.set_seed(42)\n",
    "\n",
    "N = 10000  # size of training data\n",
    "M = 128    # batch size during training\n",
    "D = 10     # number of features\n",
    "\n",
    "w_true = np.ones(D) * 5\n",
    "X_train, y_train = build_toy_dataset(N, w_true)\n",
    "X_test, y_test = build_toy_dataset(235, w_true)\n",
    "\n",
    "data = generator([X_train, y_train], M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(next(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(next(data)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
